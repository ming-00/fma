{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [CS3244 Project on music genre classificaiton](https://github.com/markusyeo/fma)\n",
    "\n",
    "Markus Yeo, Sunny Low\n",
    "\n",
    "## Creation\n",
    "\n",
    "From `raw_*.csv`, this notebook generates:\n",
    "* `tracks.csv`: per-track / album / artist metadata / filtered to fma_small.\n",
    "* `genres.csv`: genre hierarchy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import ast\n",
    "import pickle\n",
    "\n",
    "import IPython.display as ipd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from dotenv import dotenv_values \n",
    "import utils\n",
    "import creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUDIO_DIR = dotenv_values()['AUDIO_DIR']\n",
    "BASE_DIR = os.path.abspath(os.path.dirname(AUDIO_DIR))\n",
    "FMA_SMALL = os.path.join(BASE_DIR, 'fma_small')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUDIO_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.walk(AUDIO_DIR)\n",
    "filelist = []\n",
    "for root, dirs, files in path:\n",
    "\tfor file in files:\n",
    "        #append the file name to the list\n",
    "\t\tif '.mp3' in file:\n",
    "\t\t\tfilelist.append(int(file[:-4]))\n",
    "filelist = tuple(filelist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filelist[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ./creation.py metadata\n",
    "# ./creation.py data /path/to/fma/fma_full\n",
    "# ./creation.py clips /path/to/fma\n",
    "\n",
    "#!cat creation.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converters={'genres': ast.literal_eval}\n",
    "tracks = pd.read_csv('./data/fma_metadata/raw_tracks.csv', index_col=0)\n",
    "albums = pd.read_csv('./data/fma_metadata/raw_albums.csv', index_col=0)\n",
    "artists = pd.read_csv('./data/fma_metadata/raw_artists.csv', index_col=0)\n",
    "genres = pd.read_csv('./data/fma_metadata/raw_genres.csv', index_col=0)\n",
    "\n",
    "# not_found = pickle.load(open('not_found.pickle', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in [98565, 98567, 98569, 99134, 108925, 133297]: \n",
    "    filelist = list(filelist)\n",
    "    filelist.remove(i)\n",
    "filelist = tuple(filelist)\n",
    "tracks = tracks.loc[list(filelist)]\n",
    "tracks = tracks.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fs_tids(audio_dir):\n",
    "    tids = []\n",
    "    for _, dirnames, files in os.walk(audio_dir):\n",
    "        if dirnames == []:\n",
    "            tids.extend(int(file[:-4]) for file in files)\n",
    "    return tids\n",
    "\n",
    "audio_tids = get_fs_tids(FMA_SMALL)\n",
    "clips_tids = get_fs_tids(FMA_SMALL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('tracks: {} collected ({} max id)'.format(\n",
    "    len(tracks), tracks.index.max()))\n",
    "print('albums: {} collected ({} in tracks)'.format(\n",
    "    len(albums), len(tracks['album_id'].unique())))\n",
    "print('artists: {} collected ({} in tracks)'.format(\n",
    "    len(artists), len(tracks['artist_id'].unique())))\n",
    "print('genres: {} collected'.format(len(genres)))\n",
    "\n",
    "print('audio: {} collected ({} not in tracks)'.format(\n",
    "    len(audio_tids), len(set(audio_tids).difference(tracks.index))))\n",
    "print('clips: {} collected ({} not in tracks)'.format(\n",
    "    len(clips_tids), len(set(clips_tids).difference(tracks.index))))\n",
    "# assert sum(tracks.index.isin(audio_tids)) == len(tracks)\n",
    "# assert sum(tracks.index.isin(clips_tids)) == sum(tracks.index.isin(audio_tids))\n",
    "# assert len(clips_tids) == len(tracks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 5\n",
    "ipd.display(tracks.head(N))\n",
    "ipd.display(albums.head(N))\n",
    "ipd.display(artists.head(N))\n",
    "ipd.display(genres.head(N))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Format metadata\n",
    "\n",
    "Todo:\n",
    "* Sanitize values, e.g. list of words for tags, valid links in `artist_wikipedia_page`, remove html markup in free-form text.\n",
    "    * Clean tags. E.g. some tags are just artist names.\n",
    "* Fill metadata about encoding: length, number of samples, sample rate, bit rate, channels (mono/stereo), 16bits?.\n",
    "* Update duration from audio\n",
    "    * 2624 is marked as 05:05:50 (18350s) although it is reported as 00:21:15.15 by ffmpeg.\n",
    "    * 112067: 3714s --> 01:59:55.06, 112808: 3718s --> 01:59:59.56\n",
    "    * ffmpeg: Estimating duration from bitrate, this may be inaccurate\n",
    "    * Solution, decode the complete mp3: `ffmpeg -i input.mp3 -f null -`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df, column = tracks, 'tags'\n",
    "null = sum(df[column].isnull())\n",
    "print('{} null, {} non-null'.format(null, df.shape[0] - null))\n",
    "df[column].value_counts().head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Helper functions\n",
    "def convert_datetime(df, column, format=None):\n",
    "    df[column] = pd.to_datetime(df[column], infer_datetime_format=True, format=format)\n",
    "\n",
    "def convert_genres(genres):\n",
    "    genres = ast.literal_eval(genres)\n",
    "    return [int(genre['genre_id']) for genre in genres]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drops = [\n",
    "    'artist_website', 'license_image_file', 'license_image_file_large', \n",
    "    'license_parent_id', 'license_title', 'license_url', 'track_copyright_p', 'track_copyright_c', \n",
    "    'track_file', 'track_image_file',  # used to download only\n",
    "    'track_url', 'album_url', 'artist_url',  # only relevant on website\n",
    "    'track_composer', 'track_lyricist', 'track_publisher',  # present for ~4000, <1000 and <2000 tracks\n",
    "    'track_disc_number',  # different from 1 for <1000 tracks\n",
    "    'track_explicit', 'track_explicit_notes',  # present for <4000 tracks\n",
    "    'track_instrumental'  # ~6000 tracks have a 1, there is an instrumental genre\n",
    "]\n",
    "tracks.drop(drops, axis=1, inplace=True)\n",
    "tracks.rename(columns={'tags': 'track_tags'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks['track_duration'] = tracks['track_duration'].map(creation.convert_duration)\n",
    "convert_datetime(tracks, 'track_date_created')\n",
    "convert_datetime(tracks, 'track_date_recorded')\n",
    "tracks['album_id'].fillna(-1, inplace=True)\n",
    "tracks['track_bit_rate'].fillna(-1, inplace=True)\n",
    "tracks = tracks.astype({'album_id': int, 'track_bit_rate': int})\n",
    "tracks['track_genres'].fillna('[]', inplace=True)\n",
    "tracks['track_genres'] = tracks['track_genres'].map(convert_genres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Albums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "albums.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop = [\n",
    "    'artist_name', 'album_url', 'artist_url',  # in tracks already (though it can be different)\n",
    "    'album_handle',\n",
    "    'album_image_file', 'album_images',  # todo: shall be downloaded\n",
    "    #'album_producer', 'album_engineer',  # present for ~2400 albums only\n",
    "]\n",
    "albums.drop(drop, axis=1, inplace=True)\n",
    "albums.rename(columns={'tags': 'album_tags'}, inplace=True)\n",
    "convert_datetime(albums, 'album_date_created')\n",
    "convert_datetime(albums, 'album_date_released')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "albums.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Artists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "artists.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop = [\n",
    "    'artist_website', 'artist_url',  # in tracks already (though it can be different)\n",
    "    'artist_handle',\n",
    "    'artist_image_file', 'artist_images',  # todo: shall be downloaded\n",
    "    'artist_donation_url', 'artist_paypal_name', 'artist_flattr_name',  # ~1600 & ~400 & ~70, not relevant\n",
    "    'artist_contact',  # ~1500, not very useful data\n",
    "    'artist_active_year_begin', 'artist_active_year_end',  # ~1400, ~500 only\n",
    "    'artist_associated_labels',  # ~1000\n",
    "    'artist_related_projects',  # only ~800, but can be combined with bio\n",
    "]\n",
    "artists.drop(drop, axis=1, inplace=True)\n",
    "artists.rename(columns={'tags': 'artist_tags'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert_datetime(artists, 'artist_date_created')\n",
    "# for column in ['artist_active_year_begin', 'artist_active_year_end']:\n",
    "#     artists[column].replace(0.0, np.nan, inplace=True)\n",
    "#     convert_datetime(artists, column, format='%Y.0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "artists.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Merge DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks = tracks.merge(albums, left_on='album_id', right_index=True, sort=False, how='left', suffixes=('', '_dup'))\n",
    "\n",
    "n = tracks['album_title_dup'].isnull().sum()\n",
    "print('{} tracks without extended album information ({} tracks without album_id)'.format(n, sum(tracks['album_id'] == -1)))\n",
    "# assert sum(tracks['album_id'].isin(not_found['albums'])) == n\n",
    "# assert sum(tracks['album_title'] != tracks['album_title_dup']) == n\n",
    "\n",
    "tracks.drop('album_title_dup', axis=1, inplace=True)\n",
    "# assert not any('dup' in col for col in tracks.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Album artist can be different than track artist. Keep track artist.\n",
    "#tracks[tracks['artist_name'] != tracks['artist_name_dup']].select(lambda x: 'artist_name' in x, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks = tracks.merge(artists, left_on='artist_id', right_index=True, sort=False, how='left', suffixes=('', '_dup'))\n",
    "\n",
    "n = tracks['artist_name_dup'].isnull().sum()\n",
    "print('{} tracks without extended artist information'.format(n))\n",
    "# assert sum(tracks['artist_id'].isin(not_found['artists'])) == n\n",
    "assert sum(tracks['artist_name'] != tracks[('artist_name_dup')]) == n\n",
    "\n",
    "tracks.drop('artist_name_dup', axis=1, inplace=True)\n",
    "# assert not any('dup' in col for col in tracks.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = []\n",
    "for name in tracks.columns:\n",
    "    names = name.split('_')\n",
    "    columns.append((names[0], '_'.join(names[1:])))\n",
    "tracks.columns = pd.MultiIndex.from_tuples(columns)\n",
    "# assert all(label in ['track', 'album', 'artist'] for label in tracks.columns.get_level_values(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Todo: fill other columns ?\n",
    "tracks['album', 'tags'].fillna('[]', inplace=True)\n",
    "tracks['artist', 'tags'].fillna('[]', inplace=True)\n",
    "\n",
    "columns = [('album', 'favorites'), ('album', 'comments'), ('album', 'listens'), ('album', 'tracks'),\n",
    "           ('artist', 'favorites'), ('artist', 'comments')]\n",
    "for column in columns:\n",
    "    tracks[column].fillna(-1, inplace=True)\n",
    "columns = {column: int for column in columns}\n",
    "tracks = tracks.astype(columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Data cleaning\n",
    "\n",
    "Todo: duplicates (metadata and audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keep(index, df):\n",
    "    old = len(df)\n",
    "    df = df.loc[index]\n",
    "    new = len(df)\n",
    "    print('{} lost, {} left'.format(old - new, new))\n",
    "    return df\n",
    "\n",
    "tracks = keep(tracks.index, tracks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Errors from the `features.py` script.\n",
    "* IndexError('index 0 is out of bounds for axis 0 with size 0',)\n",
    "    * ffmpeg: Header missing\n",
    "    * ffmpeg: Could not find codec parameters for stream 0 (Audio: mp3, 0 channels, s16p): unspecified frame size. Consider increasing the value for the 'analyzeduration' and 'probesize' options\n",
    "    * tids: 117759\n",
    "* NoBackendError()\n",
    "    * ffmpeg: Format mp3 detected only with low score of 1, misdetection possible!\n",
    "    * tids: 80015, 115235\n",
    "* UserWarning('Trying to estimate tuning from empty frequency set.',)\n",
    "    * librosa error\n",
    "    * tids: 1440, 26436, 38903, 57603, 62095, 62954, 62956, 62957, 62959, 62971, 86079, 96426, 104623, 106719, 109714, 114501, 114528, 118003, 118004, 127827, 130298, 130296, 131076, 135804, 154923\n",
    "* ParameterError('Filter pass-band lies beyond Nyquist',)\n",
    "    * librosa error\n",
    "    * tids: 152204, 28106, 29166, 29167, 29169, 29168, 29170, 29171, 29172, 29173, 29179, 43903, 56757, 59361, 75461, 92346, 92345, 92347, 92349, 92350, 92351, 92353, 92348, 92352, 92354, 92355, 92356, 92358, 92359, 92361, 92360, 114448, 136486, 144769, 144770, 144771, 144773, 144774, 144775, 144778, 144776, 144777"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Too short a clip, known issue in wiki page\n",
    "FAILED = [98565, 98567, 98569, 99134, 108925, 133297]\n",
    "tracks = keep(tracks.index.difference(FAILED), tracks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(tracks['track', 'title'].duplicated())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genres.drop(['genre_handle', 'genre_color'], axis=1, inplace=True)\n",
    "genres.rename(columns={'genre_parent_id': 'parent', 'genre_title': 'title'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genres['parent'].fillna(0, inplace=True)\n",
    "genres = genres.astype({'parent': int})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 13 (Easy Listening) has parent 126 which is missing\n",
    "# --> a root genre on the website, although not in the genre menu\n",
    "genres.at[13, 'parent'] = 0\n",
    "\n",
    "# 580 (Abstract Hip-Hop) has parent 1172 which is missing\n",
    "# --> listed as child of Hip-Hop on the website\n",
    "genres.at[580, 'parent'] = 21\n",
    "\n",
    "# 810 (Nu-Jazz) has parent 51 which is missing\n",
    "# --> listed as child of Easy Listening on website\n",
    "genres.at[810, 'parent'] = 13\n",
    "\n",
    "# 763 (Holiday) has parent 763 which is itself\n",
    "# --> listed as child of Sound Effects on website\n",
    "genres.at[763, 'parent'] = 16\n",
    "\n",
    "# Todo: should novelty be under Experimental? It is alone on website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Genre 806 (hiphop) should not exist. Replace it by 21 (Hip-Hop).\n",
    "print('{} tracks have genre 806'.format(\n",
    "    sum(tracks['track', 'genres'].map(lambda genres: 806 in genres))))\n",
    "def change_genre(genres):\n",
    "    return [genre if genre != 806 else 21 for genre in genres]\n",
    "tracks['track', 'genres'] = tracks['track', 'genres'].map(change_genre)\n",
    "genres.drop(806, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_parent(genre, track_all_genres=None):\n",
    "    parent = genres.at[genre, 'parent']\n",
    "    if track_all_genres is not None:\n",
    "        track_all_genres.append(genre)\n",
    "    return genre if parent == 0 else get_parent(parent, track_all_genres)\n",
    "\n",
    "# Get all genres, i.e. all genres encountered when walking from leafs to roots.\n",
    "def get_all_genres(track_genres):\n",
    "    track_all_genres = list()\n",
    "    for genre in track_genres:\n",
    "        get_parent(genre, track_all_genres)\n",
    "    return list(set(track_all_genres))\n",
    "\n",
    "tracks['track', 'genres_all'] = tracks['track', 'genres'].map(get_all_genres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of tracks per genre.\n",
    "def count_genres(subset=tracks.index):\n",
    "    count = pd.Series(0, index=genres.index)\n",
    "    for _, track_all_genres in tracks.loc[subset, ('track', 'genres_all')].items():\n",
    "        for genre in track_all_genres:\n",
    "            count[genre] += 1\n",
    "    return count\n",
    "\n",
    "genres['#tracks'] = count_genres()\n",
    "genres[genres['#tracks'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_genre(track_genres):\n",
    "    top_genres = set(genres.at[genres.at[genre, 'top_level'], 'title'] for genre in track_genres)\n",
    "    return top_genres.pop() if len(top_genres) == 1 else np.nan\n",
    "\n",
    "# Top-level genre.\n",
    "genres['top_level'] = genres.index.map(get_parent)\n",
    "tracks['track', 'genre_top'] = tracks['track', 'genres'].map(get_top_genre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genres.head(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 Small Dataset\n",
    "\n",
    "Main characteristic: genre balanced.\n",
    "\n",
    "Choices:\n",
    "* 8 genres with 1000 tracks --> 8,000 tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fma_small = pd.DataFrame(tracks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SUBSETS = ['small']\n",
    "tracks['set', 'subset'] = pd.Series().astype(pd.CategoricalDtype( categories=SUBSETS, ordered=True))\n",
    "tracks.loc[fma_small.index, ('set', 'subset')] = 'small'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6 Splits: training, validation, test\n",
    "\n",
    "Take into account:\n",
    "* Artists may only appear on one side.\n",
    "* Stratification: ideally, all characteristics (#tracks per artist, duration, sampling rate, information, bio) and targets (genres, tags) should be equally distributed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks.loc[training.index, ('set', 'split')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fast_ml.model_development import train_valid_test_split\n",
    "training, _, validation, _, test, _ = train_valid_test_split(temp_tracks, train_size=0.8, valid_size=0.1, test_size=0.1, target=('track','genre_top'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.split(temp_tracks.sample(frac=1, random_state=42), [splits[0], splits[1]+splits[0]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_genre_id(genre):\n",
    "    return genres[genres['title']==genre].index[0]\n",
    "\n",
    "for genre in [get_genre_id(g) for g in tracks[('track', 'genre_top')]]:\n",
    "    tracks['genre', genres.at[genre, 'title']] = tracks['track', 'genres_all'].map(lambda genres: genre in genres)\n",
    "    \n",
    "SPLITS = ('training', 'test', 'validation')\n",
    "PERCENTAGES = (0.8, 0.1, 0.1)\n",
    "tracks['set', 'split'] = pd.Series(dtype = pd.CategoricalDtype(categories=SPLITS))\n",
    "\n",
    "genre_list = list(tracks[('track', 'genre_top')].unique())\n",
    "\n",
    "while True:\n",
    "    if len(genre_list) == 0:\n",
    "        break\n",
    "\n",
    "    # Choose most constrained genre, i.e. genre with the least unassigned artists.\n",
    "    tracks_unsplit = tracks['set', 'split'].isnull()\n",
    "    temp = tracks.loc[tracks.index.intersection(tracks_unsplit.index, sort=False)].set_index(('artist', 'id'), append=True)['genre']\n",
    "    count = temp.groupby(level=1).sum().astype(bool).sum()\n",
    "    genre = count[genre_list].idxmin()\n",
    "    if genre in genre_list:\n",
    "        genre_list.remove(genre)\n",
    "    \n",
    "    # Given genre, select artists.\n",
    "    tracks_genre = tracks[tracks[('genre', genre)] == True]\n",
    "    \n",
    "    artists = tracks.loc[temp.index.get_level_values(level='track_id').intersection(tracks_genre.index, sort=False), ('artist', 'id')].value_counts()\n",
    "    #print('-->', genre, len(artists))\n",
    "\n",
    "    current = {split: np.count_nonzero(tracks.index.intersection(tracks_genre.index, sort=False).intersection(tracks[tracks['set', 'split'] == split].index)) for split in SPLITS}\n",
    "    # print(current)\n",
    "\n",
    "    # Only classify artists with more than 10 songs into training, validation, and test sets.\n",
    "    remainder = []\n",
    "    for artist, count in artists.items():\n",
    "        temp_tracks = tracks.loc[tracks.loc[tracks['artist', 'id'] == artist].index.intersection(tracks_genre.index, sort=False)]\n",
    "        if len(temp_tracks) >= 10:\n",
    "            training, validation, test = np.split(temp_tracks.sample(frac=1, random_state=42), [int(.8*len(temp_tracks)), int(.9*len(temp_tracks))])\n",
    "            current['training'] += len(training)\n",
    "            tracks.loc[training.index, ('set', 'split')] = 'training'\n",
    "            current['test'] += len(test)\n",
    "            tracks.loc[test.index, ('set', 'split')] = 'test'\n",
    "            current['validation'] += len(validation)\n",
    "            tracks.loc[validation.index, ('set', 'split')] = 'validation'\n",
    "        else:\n",
    "            continue\n",
    "    temp_tracks = tracks_genre[tracks[('set','split')].isnull()]\n",
    "    splits = [len(tracks_genre)*percentage for percentage in PERCENTAGES]\n",
    "    splits = [int(split) - current[SPLITS[i]] for i, split in enumerate(splits)]\n",
    "    print(splits)\n",
    "    training, validation, test = np.split(temp_tracks.sample(frac=1, random_state=42), [splits[0], splits[2]+splits[0]])\n",
    "    current['training'] += len(training)\n",
    "    tracks.loc[training.index, ('set', 'split')] = 'training'\n",
    "    current['test'] += len(test)\n",
    "    tracks.loc[test.index, ('set', 'split')] = 'test'\n",
    "    current['validation'] += len(validation)\n",
    "    tracks.loc[validation.index, ('set', 'split')] = 'validation'\n",
    "    \n",
    "    print(current)\n",
    "# Not needed any more.\n",
    "tracks.drop('genre', axis=1, level=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks['set','split'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7 Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('./data/fma_metadata')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in 'tracks', 'genres':\n",
    "    eval(dataset).sort_index(axis=0, inplace=True)\n",
    "    eval(dataset).sort_index(axis=1, inplace=True)\n",
    "    params = dict(float_format='%.10f') if dataset == 'echonest' else dict()\n",
    "    eval(dataset).to_csv(dataset + '.csv', **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ./creation.py normalize /path/to/fma\n",
    "# ./creation.py zips /path/to/fma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8 Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "tracks = utils.load('tracks.csv')\n",
    "tracks.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 5\n",
    "ipd.display(tracks['track'].head(N))\n",
    "ipd.display(tracks['album'].head(N))\n",
    "ipd.display(tracks['artist'].head(N))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
